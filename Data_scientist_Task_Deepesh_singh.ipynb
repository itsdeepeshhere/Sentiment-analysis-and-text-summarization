{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59e481ff",
   "metadata": {},
   "source": [
    "### Importing Libraries-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be942ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Deepesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Deepesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985761f8",
   "metadata": {},
   "source": [
    "### Sentiment Analysis -\n",
    "This function takes a review as input and uses TextBlob to calculate the sentiment polarity. The polarity score ranges from -1 (negative) to +1 (positive), indicating the sentiment of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6f1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(review_text):\n",
    "    #Evaluate the sentiment polarity of a review using TextBlob\n",
    "    return TextBlob(review_text).sentiment.polarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c613dd0e",
   "metadata": {},
   "source": [
    "### Topic Extraction-\n",
    "The function tokenizes the review text into words, removes stopwords (common words that don't contribute much meaning), and then finds the most common words. These common words are considered as the main topics of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c0e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic(review_text):\n",
    "    #Extracting the most common topics from a review using NLTK\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(review_text.lower())\n",
    "    relevant_words = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "    top_words = Counter(relevant_words).most_common(3)\n",
    "    extracted_topics = [word for word, _ in top_words]\n",
    "    return ', '.join(extracted_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173a7a9",
   "metadata": {},
   "source": [
    "### Summarization-\n",
    "The reviews are combined into a single text and then summarized using the Latent Semantic Analysis (LSA) algorithm from the sumy library. The sentences_count parameter controls the number of sentences in the summary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124f3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(reviews_list):\n",
    "    #Generating a summary of reviews for a college using Sumy's LSA summarizer\n",
    "    combined_reviews = ' '.join(reviews_list)\n",
    "    parser = PlaintextParser.from_string(combined_reviews, Tokenizer(\"english\"))\n",
    "    summarizer = LsaSummarizer()\n",
    "    summary = summarizer(parser.document, sentences_count=3)  # can be adjusted the number of sentences as needed\n",
    "    return ' '.join([str(sentence) for sentence in summary])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badfe50",
   "metadata": {},
   "source": [
    "### Processing Data-\n",
    "It applies the sentiment analysis and topic extraction functions to each review and adds the results as new columns in the DataFrame.\n",
    "For each college, it generates a summary of all reviews and stores the results in a new DataFrame.\n",
    "Finally, it saves the updated data and summaries to Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2080f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
      "C:\\Users\\Deepesh\\AppData\\Local\\Temp\\ipykernel_12000\\3147339034.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurray! Tasks completed.\n"
     ]
    }
   ],
   "source": [
    "def process_data():\n",
    "    # Loading the dataset\n",
    "    data = pd.read_excel('Sample_Interview.xlsx')\n",
    "\n",
    "    #Applying sentiment analysis and topic extraction\n",
    "    data['polarity'] = data['Review'].apply(sentiment_analysis)\n",
    "    data['topic'] = data['Review'].apply(extract_topic)\n",
    "\n",
    "\n",
    "    # Generating summaries for each college\n",
    "    summary_data = pd.DataFrame(columns=['college_name', 'review_summary'])\n",
    "    for college, group in data.groupby('college_name'):\n",
    "            summary = generate_summary(group['Review'])\n",
    "            summary_data = summary_data.append({'college_name': college, 'review_summary': summary}, ignore_index=True)\n",
    "\n",
    "\n",
    "    # Saving the updated data and summaries\n",
    "    data.to_excel('Output_Sample_Interview.xlsx', index=False)\n",
    "    summary_data.to_excel('College_Summary.xlsx', index=False)\n",
    "\n",
    "    print(\"Hurray! Tasks completed.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd798932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
